{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Lesson 2: Image Editing & Memory Management\n",
    "\n",
    "In this lesson, we will dive into **Image-to-Image** translation and learn how to handle heavy models on consumer hardware (managing VRAM).\n",
    "\n",
    "### What we'll learn:\n",
    "1. The Math of the `strength` parameter\n",
    "2. Visualizing Latent Noise\n",
    "3. Memory optimization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "project_root = Path(os.getcwd()).parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from core.pipeline import pipeline_manager\n",
    "from core.image_editor import image_editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load an Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image (a sketch of a cat)\n",
    "url = \"https://raw.githubusercontent.com/CompVis/stable-diffusion/main/assets/stable-samples/img2img/sketch-mountains-input.jpg\"\n",
    "response = requests.get(url)\n",
    "input_image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "input_image = input_image.resize((512, 512))\n",
    "input_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Science of 'Strength' (Noise Injection)\n",
    "\n",
    "How does Image-to-Image work mathematically?\n",
    "\n",
    "1. We encode the image to latents $z_0$.\n",
    "2. We add noise to it based on `strength` ($s$).\n",
    "\n",
    "$$z_t = \\sqrt{1-s} \\cdot z_0 + \\sqrt{s} \\cdot \\epsilon$$\n",
    "\n",
    "Let's visualize this corruption process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the pipeline\n",
    "pipe = pipeline_manager.get_img2img_pipeline()\n",
    "\n",
    "# Create noise\n",
    "img_arr = np.array(input_image) / 255.0\n",
    "noise = np.random.normal(0, 1, img_arr.shape)\n",
    "\n",
    "# Simulate 'strength' visually (in pixel space for demonstration)\n",
    "def show_noisy_image(strength):\n",
    "    # Simple linear mix for visualization\n",
    "    noisy = (1 - strength) * img_arr + strength * noise\n",
    "    # Clip to valid range\n",
    "    noisy = np.clip(noisy, 0, 1)\n",
    "    return Image.fromarray((noisy * 255).astype(np.uint8))\n",
    "\n",
    "print(\"Visualizing Strength = 0.3 (Mostly original):\")\n",
    "display(show_noisy_image(0.3))\n",
    "\n",
    "print(\"Visualizing Strength = 0.8 (Mostly noise):\")\n",
    "display(show_noisy_image(0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Editing the Image\n",
    "\n",
    "Now let's actually run the model. Notice how `strength=0.75` implies we start with a very noisy image, giving the model freedom to hallucinate new details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A beautiful realistic mountain landscape, 8k, photorealistic, sunset\"\n",
    "\n",
    "# Try with strength 0.75\n",
    "result, _ = image_editor.edit_image(\n",
    "    image=input_image,\n",
    "    prompt=prompt,\n",
    "    strength=0.75,\n",
    "    num_steps=30\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Memory Optimization (Concepts)\n",
    "\n",
    "Stable Diffusion requires a lot of VRAM. If you are running on a card with less than 8GB VRAM, you might encounter `OutOfMemory` errors.\n",
    "\n",
    "Our project handles this in `core/memory_manager.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import device_config\n",
    "print(f\"Attention Slicing: {device_config.enable_attention_slicing}\")\n",
    "print(f\"VAE Tiling: {device_config.enable_vae_tiling}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
