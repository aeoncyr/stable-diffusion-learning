{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udfe2 Lesson 2: Tensors and Devices\n",
    "\n",
    "Before generating art, we must speak the language of the machine: **PyTorch Tensors**.\n",
    "\n",
    "### Goals:\n",
    "1.  Understand what a **Tensor** is.\n",
    "2.  Check for **GPU Acceleration** (DirectML/CUDA).\n",
    "3.  Understand precision types (`float32` vs `float16`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Setup\n",
    "import notebook_utils\n",
    "project_root, device, dtype = notebook_utils.setup_notebook()\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Tensor?\n",
    "\n",
    "A Tensor is just a multi-dimensional matrix that can live on a graphics card (GPU).\n",
    "\n",
    "- **Scalar**: `5` (0 dimensions)\n",
    "- **Vector**: `[1, 2, 3]` (1 dimension)\n",
    "- **Matrix**: `[[1, 2], [3, 4]]` (2 dimensions)\n",
    "- **Image Tensor**: `(Height, Width, Color Channels)` (3 dimensions)\n",
    "- **Batch of Images**: `(Batch Size, Height, Width, Colors)` (4 dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random tensor\n",
    "x = torch.rand(3, 3)\n",
    "print(\"Random 3x3 Matrix:\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Moving to the GPU\n",
    "\n",
    "Deep Learning involves billions of multiplications. CPUs are smart but slow at parallel math. GPUs are dumb but incredibly fast at parallel math.\n",
    "\n",
    "We use `torch-directml` to access your AMD GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Active Device: {device}\")\n",
    "\n",
    "# Move the tensor to the GPU\n",
    "x_gpu = x.to(device)\n",
    "print(f\"Tensor is now on: {x_gpu.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Precision (FP32 vs FP16)\n",
    "\n",
    "- **FP32 (Single Precision)**: Standard for math. Uses 4 bytes per number. High accuracy.\n",
    "- **FP16 (Half Precision)**: Uses 2 bytes per number. Slightly less accurate, but **2x Faster** and **uses 50% less VRAM**.\n",
    "\n",
    "Stable Diffusion is robust enough to run comfortably on FP16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP32\n",
    "a_32 = torch.tensor([1.5555555], dtype=torch.float32)\n",
    "print(f\"FP32: {a_32.item()}\")\n",
    "\n",
    "# FP16\n",
    "a_16 = a_32.to(torch.float16)\n",
    "print(f\"FP16: {a_16.item()} (Notice the loss of precision!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Now that we know how to move data to the GPU, let's load the actual AI models in Lesson 3!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nbformat": 4,
  "nbformat_minor": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}